{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import trapz\n",
    "from scipy.integrate import quad\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy import optimize\n",
    "\n",
    "import scipy.io as sio\n",
    "from statsmodels.stats.weightstats import DescrStatsW\n",
    "import math\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal(x,mu,sigma):\n",
    "  d=1/(sigma * np.sqrt(2 * np.pi)) * np.exp( - (x - mu)**2 / (2 * sigma**2) )\n",
    "\n",
    "  return d\n",
    "\n",
    "\n",
    "def triad_trpz(f, a, b,p0,p1, n=1000):\n",
    "  h = (b - a) / n\n",
    "  s=np.linspace(a,b,n)\n",
    "  integ1= (f(a,p0,p1)+f(b,p0,p1))/2.0\n",
    "  integ2=f(s,p0,p1)\n",
    "  integ2=sum(integ2)\n",
    "\n",
    "  integral=(integ1+integ2)*h\n",
    "  return integral\n",
    "def pantad_trpz(f, a, b,p0,p1,p2,p3 ,n=1000):\n",
    "  h = float(b - a) / n\n",
    "  s=np.linspace(a,b,n)\n",
    "  integ1= (f(a,p0,p1,p2,p3)/2.0)+(f(b,p0,p1,p2,p3)/2.0)\n",
    "  integ_2=[f(x,p0,p1,p2,p3) for x in s]\n",
    "  integ_2=sum(integ_2)\n",
    "  integral=((integ1+integ_2)*h)\n",
    "  return (integral)\n",
    "def trpz(f, a, b, n=1000):\n",
    "  h = float(b - a) / n\n",
    "  s=np.linspace(a+h,b-h,n-1)\n",
    "  integ1= (f(a)/2.0)+(f(b)/2.0)\n",
    "  integ2=f(s)\n",
    "  integ2=np.sum(integ2)\n",
    "  integral=(integ1+integ2)*h\n",
    "  return integral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p1_new(t_m,t_s,w_m):\n",
    "  return normal(t_m,t_s,t_s*w_m)\n",
    "  \n",
    "def p1_new_modified(t_m,t_s,w_m):\n",
    "  return t_m * normal(t_m,t_s,t_s*w_m)\n",
    "\n",
    "def p2_new(t_e,t_p,w_p):\n",
    "  return normal(t_p,t_e,t_e*w_p)\n",
    "\n",
    "def f_bls(ts,wm,tmin=0.4,tmax=1):\n",
    "  y1_integ=triad_trpz(p1_new_modified,tmin,tmax,ts,wm)\n",
    "  y2_integ=triad_trpz(p1_new,tmin,tmax,ts,wm)+(10**(-52))\n",
    "  return (y1_integ/y2_integ)\n",
    "\n",
    "def f_mle(tm,wm):\n",
    "  return tm*((-1+np.sqrt(1+4*wm**2))/(2*wm**2))\n",
    "\n",
    "def combined_mle(tm,tp,ts,wp,wm):\n",
    "  return p1_new(tm,ts,wm)*p2_new(f_mle(ts,wm),tp,wp)\n",
    "\n",
    "def combined_bls(tm,tp,ts,wp,wm):\n",
    "  return (p1_new(tm,ts,wm)*p2_new(f_bls(ts,wm),tp,wp))\n",
    "\n",
    "def bayesian(tp,ts,wp,wm):\n",
    "  return pantad_trpz(combined_bls,-50,+50,tp,ts,wp,wm)\n",
    "\n",
    "def bayesian_mle(tp,ts,wp,wm):\n",
    "  return pantad_trpz(combined_mle,-50,+50,tp,ts,wp,wm)\n",
    "\n",
    "def distractor(ts,td,k):\n",
    "  return (ts+td*(k**(abs(ts-td))))/(1+(k**(abs(ts-td))))\n",
    "\n",
    "def bayesian_new(tp,ts,td,wp,wm,k):\n",
    "  return pantad_trpz(combined_bls,-50,+50,tp,distractor(ts,td,k),wp,wm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reader(dir):\n",
    "  df=pd.read_csv(dir)\n",
    "  df=df.dropna()\n",
    "  df_500=df.query('random_gaps==0.5')\n",
    "  df_900=df.query('random_gaps==0.9')\n",
    "  df_1700=df.query('random_gaps==1.7')\n",
    "  l_tp500=vectorize_data(df_500)\n",
    "  l_tp900=vectorize_data(df_900)\n",
    "  l_tp1700=vectorize_data(df_1700)\n",
    "  return [[l_tp500,l_tp900,l_tp1700],len(df)]\n",
    "\n",
    "  \n",
    "def vectorize_data(df):\n",
    "  #l_tp=np.array(df['t_prod'])\n",
    "  t_p400=np.array(df.query('t_sample==0.4')['t_prod'])\n",
    "  t_p600=np.array(df.query('t_sample==0.6')['t_prod'])\n",
    "  t_p1000=np.array(df.query('t_sample==1')['t_prod'])\n",
    "  l_tp=[t_p400,t_p600,t_p1000]\n",
    "  return l_tp\n",
    "\n",
    "def fitter_plotter(dir):\n",
    "  df=pd.read_csv(dir)\n",
    "  df=df.dropna()\n",
    "  df_500=df.query('random_gaps==0.5')\n",
    "  df_900=df.query('random_gaps==0.9')\n",
    "  df_1700=df.query('random_gaps==1.7')\n",
    "  l_tp500=vectorize_data(df_500)\n",
    "  l_tp900=vectorize_data(df_900)\n",
    "  l_tp1700=vectorize_data(df_1700)\n",
    "  bnds = ((0, 1), (0, 1),(0,1))\n",
    "  minimum= optimize.minimize(log_like_2,[0.3,0.3,0.3],args=(l_tp500,l_tp900,l_tp1700),bounds=bnds,method='Nelder-Mead')\n",
    "  print('our fitted parameters ',minimum)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
